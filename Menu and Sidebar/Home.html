<HTML>
	<HEAD>
		<LINK REL="stylesheet" TYPE="text/css" HREF="../Menu and Sidebar/Misc/main.css">
	</HEAD>
	
	<BODY>
		<DIV CLASS="main">

			<H1>Quotes</H1>
		
				<UL>		
					<LI>I’m seen as a problem solver. When something’s broken or running slow, I’m usually called in. The bad news is that it’s because they’re blaming the database, but the good news is that I can help get to the real root cause. When I do it right, I’m seen as a helper and a facilitator, not a blame-game guy.</LI><BR />
					<LI>Ability may get you to the top, but it takes character to keep you there.</LI><BR />
					<LI>If I do the job for only 30 minutes, it's because I spent 7 years learning how to do that in 30 minutes. You owe me for the years, not the minutes.</LI><BR />
					<LI>I am in competition with no one. I have no desire to play the game of being better than anyone. I am simply trying to be better than the person I was yesterday.</LI><BR />
					<LI>Whether you're a DBA, a developer, a project manager, or a tester, whatever field you're in, you need to be wildly passionate about it. This isn't something you're going to learn, but I mention it because it's the only way you can succeed in a job like this. If I only worked with databases from 8:30am to 5:30pm, five days a week, I would be way behind. I work a lot more, but because it doesn't feel like work to me. I love what I do. So working 50-70 hours a week doesn't feel like work - it feels like a hobby too.</LI><BR />
					<LI>Every year, there's going to be some sexy and new technology. Your friends are going to be all over it, and they're going to be "...ooh"ing and "..aah"ing at how cool and new it is. They're going to spend all their spare time learning how to use it, but since this is new, there's not going to be any established "right way" of doing it, so most of them will be doing it wrong. When the standards come out, they're going to spend more time relearning it - but because there are standards, it's going to lose sex appeal, and you're friends will be off to the next shiny new technology. I'm not saying you should stop learning, but you should focus your learning on a very small surface area, and dive deeply into that subject. At the end of ten years, you can either be a junior guy in half a dozen languages, or a very senior guy in one. Guess which one is worth more money.</LI><BR />
					<LI>It's not the strongest of the species that survive, nor the most intelligent, but the one most responsive to change.</LI><BR />
					<LI>Police don't make the law - they just enforce it. Likewise, the DBA needs to serve and protect the data. I didn't say you had to fix the bottlenecks - I just said you need to know how to fix them. The actual process of fixing them is sa business decision: the business has to be  willing to spend the money and time to make their server go faster. your responsibility is just to have the answer when the business asks, "Why is the server slow, and how can we make it faster?"</LI><BR />
					<LI>Documentation is a love letter you write to your future self.</LI><BR />
				</UL>
				
			<H1>To Do List</H1>
			
				<UL>
					<LI>Use ChatGPT to define most commonly used Execution Plan Operators.</LI>
					<LI>Create a separate header on the top in tempdb topic for the best/worst practices.</LI>
				</UL>
				
			<H1>Did you know?!</H1>
			
				<H2>IaaS vs. PaaS</H2>

IaaS
IaaS  provides virtual machines, networking, and storage resources that you manage.
You have control over the operating system, database installations, and patch management—which aligns with your ability to install SQL Server and apply updates manually.
Examples in AWS: EC2 instances, where you set up and maintain the software stack.

PaaS
PaaS abstracts infrastructure management.
If you were using Amazon RDS (Relational Database Service) for SQL Server, AWS would handle installation, patching, and network configurations (with some limited customization).
You’d only manage the database and its configurations, not the OS or underlying VM.
			
				<H2>Predicate, Parameter, Argument</H2>

Predicate - an expression that evaluates to TRUE, FALSE, or Unknown
Parameter - a placeholder
Argument - actual value
			
				<H2>Check Index Size</H2>
SELECT 
    OBJECT_SCHEMA_NAME(i.object_id) AS SchemaName,
    OBJECT_NAME(i.object_id) AS TableName,
    i.name AS IndexName,
    i.type_desc AS IndexType,
    SUM(ps.used_page_count) * 8 AS IndexSizeKB,
    SUM(ps.used_page_count) * 8 / 1024 AS IndexSizeMB
FROM 
    sys.indexes AS i
JOIN 
    sys.dm_db_partition_stats AS ps
    ON i.object_id = ps.object_id AND i.index_id = ps.index_id
WHERE 
    i.type > 0 -- Exclude heap indexes
    AND i.is_disabled = 0 -- Exclude disabled indexes
GROUP BY 
    OBJECT_SCHEMA_NAME(i.object_id), 
    OBJECT_NAME(i.object_id), 
    i.name, 
    i.type_desc
ORDER BY 
    IndexSizeMB DESC;


			
				<H2>Buffer Cache</H2>
				
				The buffer cache (also known as the buffer pool) in SQL Server is a memory area used to store data pages that are read from the disk. The primary purpose of the buffer cache is to improve the performance of database operations by reducing the need to read data from disk, which is a much slower operation compared to accessing data from memory.

Key Functions of the Buffer Cache
Caching Data Pages: When data is read from the disk, it is stored in the buffer cache so that subsequent requests for the same data can be satisfied from memory, significantly speeding up read operations.

Caching Index Pages: Index pages are also stored in the buffer cache to speed up index lookups and improve the performance of queries that use indexes.

Minimizing Disk I/O: By keeping frequently accessed data in memory, SQL Server minimizes the number of disk I/O operations, which are relatively slow.

Concurrency Management: Multiple users and processes can access the same data pages in the buffer cache without causing data inconsistency, thanks to SQL Server's concurrency control mechanisms.

How the Buffer Cache Works
Reading Data: When a query requests data, SQL Server first checks if the data is already in the buffer cache. If it is, the data is returned directly from memory (a cache hit). If the data is not in the cache (a cache miss), SQL Server reads the data from the disk and stores it in the buffer cache for future access.

Writing Data: When data is modified, the changes are made in the buffer cache and marked as "dirty." These dirty pages are periodically written back to the disk by a background process known as the checkpoint process to ensure data durability.

Eviction Policy: The buffer cache has a limited size, so not all data can be stored in memory. SQL Server uses a least recently used (LRU) algorithm to evict pages that have not been accessed recently when new pages need to be loaded into the cache.

Buffer Cache Configuration
Memory Allocation: SQL Server dynamically manages the size of the buffer cache within the limits set by the system memory. Administrators can configure the maximum and minimum memory settings for SQL Server to control how much memory is allocated to the buffer cache.

sql
Copy
Edit
EXEC sp_configure 'max server memory', 16384; -- Set maximum server memory to 16 GB
RECONFIGURE;
Monitoring Buffer Cache: SQL Server provides several performance counters and dynamic management views (DMVs) to monitor the buffer cache usage and performance. Key DMVs include sys.dm_os_buffer_descriptors and sys.dm_os_memory_clerks.

sql
Copy
Edit
-- Example: Query buffer pool usage
SELECT
    COUNT(*) AS cached_pages_count,
    (COUNT(*) * 8.0) / 1024 AS cached_pages_in_MB
FROM
    sys.dm_os_buffer_descriptors
WHERE
    database_id = DB_ID('YourDatabaseName');
Performance Impact
The buffer cache plays a critical role in the performance of SQL Server. A well-sized buffer cache can significantly reduce disk I/O, speed up query execution, and improve overall system performance. Conversely, if the buffer cache is too small, SQL Server may experience frequent cache misses, leading to increased disk I/O and slower performance.

In summary, the buffer cache in SQL Server is a crucial component that stores data pages in memory to optimize read and write operations, reduce disk I/O, and enhance overall database performance. Proper configuration and monitoring of the buffer cache are essential for maintaining an efficient and high-performing SQL Server environment.

			
				<H2>Incorrect SQL AG Owner</H2>
				
					<BR /><IMG SRC="Misc/Incorrect SQL AG Owner.PNG" WIDTH=60% /><BR />
				
				
				<H2>Parameter Sniffing</H2>
				
					Parameter sniffing is a feature of SQL Server than can sometimes become a problem.  In some cases, it can cause poor performance of a stored procedure.  The above link has a detailed explanation, but the concept is summarized here.
SQL Server chooses an execution plan based on the particular parameter values that exist at compilation time. The implicit assumption is that parameterized statements are most commonly executed with the most common parameter values. 

				
				<H2>Optimization</H2>
				
				•	If your query takes a long time to run, that’s the first indication of inefficiency.  Review the execution plan and see if you can make it faster.
•	Try to avoid using NOT.  An index can easily help SQL Server find rows that DO match our query, but there is no index to help find all the rows that DO NOT match our query.  Using NOT usually results in one or more table scans.
•	When the needed logic allows, use EXISTS instead of COUNT.  EXISTS is much more efficient because as soon as a single match is found, the condition is satisfied.  COUNT requires SQL Server to do just that – count each matching row.  Even using COUNT > 1 requires a full COUNT to complete before the expression is evaluated
•	In many cases, a UNION ALL of multiple simple queries will perform more efficiently than one query with a complex WHERE clause with multiple OR statements.
•	Avoid LEFT OUTER JOIN when possible.  A LEFT JOIN is more likely to lead to a table scan than an INNER JOIN.
•	Avoid the DISTINCT keyword. DISTINCT is costly because each matching row in the result set must be held in memory (or worse, tempdb) and then sorted to remove duplicates.

			
				<H2>Max Degree of Parallelism</H2>
				
					<P>
						so... Edgar, for whatever reason, it started creating plans that were creating too many parallel threads.  The optimizer "thought" the plans would be more efficient, but all it did was max out the CPU.  I had to put a MAXDOP 1 hint on the two subqueries that were doing that.  (max degree of parallelism = 1) so that it would only use one thread....right.  the optimizer does a really good job most of the time, but sometimes it ... well, it does an AWFUL job.  This was one of those times.  And it can depend on the amount of data in the tables... the plan can change.
					</P>

MAXDOP (Maximum Degree of Parallelism) in SQL Server is a configuration setting that determines the maximum number of processors (cores) that can be used to execute a single query task in parallel. It is an important setting that can significantly impact the performance of SQL Server queries, especially on multi-core systems.

Key Concepts of MAXDOP
Parallel Execution: SQL Server can split a query into multiple tasks that run concurrently on different processors. This is known as parallel execution and can speed up query processing, especially for complex or long-running queries.

Degree of Parallelism: The degree of parallelism refers to the number of processors used to execute a single query task in parallel. By default, SQL Server decides how many processors to use based on the query and system workload.

Setting MAXDOP
MAXDOP can be configured at different levels:

Server Level: Configures the maximum degree of parallelism for the entire SQL Server instance. This is done using the sp_configure system stored procedure.

sql
Copy
Edit
-- Set MAXDOP to 4 for the entire server
EXEC sp_configure 'show advanced options', 1;
RECONFIGURE;
EXEC sp_configure 'max degree of parallelism', 4;
RECONFIGURE;
Query Level: Overrides the server-level setting for a specific query using the OPTION (MAXDOP n) query hint.

sql
Copy
Edit
SELECT *
FROM MyTable
OPTION (MAXDOP 2); -- Use a maximum of 2 processors for this query
Database Level: As of SQL Server 2016 (13.x) and later, you can set the MAXDOP option at the database level using the ALTER DATABASE command.

sql
Copy
Edit
ALTER DATABASE SCOPED CONFIGURATION SET MAXDOP = 4;
Considerations for Setting MAXDOP
Hardware and Workload: The optimal MAXDOP setting depends on the number of available processors and the nature of the workload. High degrees of parallelism can benefit complex queries but might lead to resource contention and reduce performance for OLTP systems with many concurrent queries.

NUMA Nodes: For systems with Non-Uniform Memory Access (NUMA) architecture, it might be beneficial to set MAXDOP to the number of cores within a NUMA node to reduce cross-node traffic and improve performance.

Resource Governor: In environments with resource pools, you can configure the MAXDOP setting for specific workloads using the Resource Governor.

sql
Copy
Edit
ALTER WORKLOAD GROUP [group_name]
WITH (MAX_DOP = 4);
Best Practices
General Guidance:

For OLTP systems, a MAXDOP value of 1 to 4 is often recommended to prevent excessive parallelism and resource contention.

For OLAP or data warehouse systems, a higher MAXDOP value might be beneficial, but it should be tested based on the specific workload and system architecture.

Testing and Monitoring: Always test the impact of changing MAXDOP settings in a non-production environment and monitor query performance using tools like SQL Server Management Studio (SSMS), Extended Events, and Dynamic Management Views (DMVs).

sql
Copy
Edit
-- Monitor currently executing queries and their degree of parallelism
SELECT
    r.session_id,
    r.start_time,
    r.total_elapsed_time,
    r.degree_of_parallelism
FROM
    sys.dm_exec_requests r
WHERE
    r.degree_of_parallelism > 1;
In summary, MAXDOP is a critical configuration setting in SQL Server that controls the level of parallelism for query execution. Properly configuring MAXDOP can enhance query performance and ensure efficient use of system resources.

			
				<H2>Cost Threshold for Parallelism</H2>
				
					<BR /><IMG SRC="Misc/Cost Threshold for Parallelism.PNG" WIDTH=60% /><BR />
			
				<H2>Checkpoint</H2>
				
					<P>
					In SQL Server, a "checkpoint" is an internal process that writes all modified data pages (considered "dirty pages") from the buffer cache to the physical disk, along with the corresponding transaction log records, essentially creating a known good state from which the database can recover if the system crashes unexpectedly, minimizing data loss during recovery; it is a mechanism to ensure database consistency by periodically saving changes to disk. 
Key points about checkpoints in SQL Server:
Purpose:
To reduce recovery time in case of a system failure by writing dirty pages and log records to disk regularly. 
How it works:
When a checkpoint occurs, all modified pages in memory are flushed to the data files, and the log records are written to the transaction log. 
Types of checkpoints:
SQL Server supports different checkpoint types including automatic (triggered based on configured settings), manual (initiated by the user), and indirect checkpoints. 
					</P>
			
			
				<H2>Key notes on how to have a clean and fast side-by-side migration</H2>

					<OL>
						<LI>Perform a full back up prior start of migration and restore it on the new server.</LI>

						<LI>Once all preparations are done and ready to disconnect all users:</LI>

<PRE>
USE master
GO

ALTER DATABASE &ltdb_name&gt
SET SINGLE_USER
WITH ROLLBACK IMMEDIATE;
GO

</PRE>
						<LI>Perform T-log backup on the old server and restore it on the new server.</LI>
					</OL>
					
				<H2>Solve Mouse Auto Double Click in Windows 10</H2>
					
					<OL>
						<LI>Go to Device Manager.</LI>
						<LI>Go to Universal Serial Bus Controller</LI>
						<LI>Choose USB Root Hub (3.0) and go to its properties.</LI>
						<LI>Uncheck "Allow the computer to turn off the device to save power.</LI>
					</OL>	
			
				<H2>Always assign rights to roles instead of users</H2>
				
					<P>Users quit. The next guy may want the same rights.</P>
				
				
				<H2>Alert Threshold Candidates</H2>
				
					<UL>
						<LI>Disk percent</LI>
						<LI>CPU time (duration)</LI>
						<LI>SQL worker threads</LI>
						<LI>Any baseline (different from normal)</LI>
					</UL>
					
				<H2>Backup</H2>
				
					<P>Use COPY_ONLY option for ad hoc backups.</P>
					
				<H2>Azure SQL Managed Instance</H2>
				
					<P>https://www.youtube.com/watch?v=sSglixbsRhs</P>
					<P>https://www.youtube.com/watch?v=W8feSZXm2Ec</P>
					<P>https://www.youtube.com/watch?v=HmiVon2gtFA</P>
					<P>https://www.youtube.com/watch?v=CuI2M8QDS1E</P>
					<P>https://www.youtube.com/@AzureSQL/videos</P>
					
				<H2>Don't assume everything's going to fine</H2>
				
					<UL>
						<LI>Silence is not always golden.</LI>
						<LI>Notification on failed jobs is not enough.</LI>
						<LI>Be careful of getting over-creative. Keep things simple.</LI>
					</UL>
			
				<H2>What Causes Recompilation</H2>
				
					<UL>
						<LI>Expected</LI>
							<UL>
								<LI><CODE>sp_recompile</CODE></LI>
								<LI><CODE>CREATE PROC or EXEC..WITH RECOMPILE</CODE></LI>
							</UL>
						<LI>Unexpected</LI>
							<UL>
								<LI>Plan was aged out of memory.</LI>
								<LI>Interleaved DDL and DML</LI>
								<LI>Big changes last execution such as:
									<UL>
										<LI>schema changes to objects in underlyring code</LI>
										<LI>new/updated index statistics</LI>
											<UL>
												<LI>Auto_Update Statistics</LI>
												<LI>Auto_Create Statistics</LI>
												<LI><CODE>UPDATE STATISTICS</CODE></LI>
											</UL>
										<LI>sp_configure</LI>
										<LI>index used by query is dropped.</LI>
									</UL></LI>
							</UL>
					</UL>
				
				<H2>Normalization</H2>
				
					<UL>
						<LI>1NF - Remove duplicate data and break data at granular level.</LI>
						<LI>2NF - All column data should depend on full primary key and not part.</LI>
						<LI>3NF - No column should depend on other columns.</LI>
					</UL>
					

				<H2>What's the difference between a Primary Key and a Unique Key</H2>
				
In a database, both a unique key and a primary key enforce uniqueness of data, but they serve different purposes and have distinct characteristics. Here are the key differences between them:

### Primary Key

1. **Uniqueness:**
   - A primary key uniquely identifies each record in a table. No two rows can have the same primary key value.

2. **Nullability:**
   - A primary key cannot contain NULL values. Every row must have a value for the primary key column(s).

3. **Index:**
   - A primary key automatically creates a unique index on the column(s). In many database systems, this is a clustered index, meaning the data is physically stored in the order of the primary key.

4. **Number per Table:**
   - Each table can have only one primary key.

5. **Purpose:**
   - The primary key is used to uniquely identify each row in the table and is often used as a reference by foreign keys in other tables.

### Unique Key

1. **Uniqueness:**
   - A unique key also enforces uniqueness for the column(s) it is defined on, ensuring that no two rows can have the same value in those columns.

2. **Nullability:**
   - Unlike a primary key, a unique key can contain NULL values. However, depending on the database system, the unique constraint may enforce that each row can have at most one NULL value (e.g., in SQL Server).

3. **Index:**
   - A unique key also creates a unique index on the column(s). This index can be either clustered or non-clustered, depending on the definition and database system.

4. **Number per Table:**
   - A table can have multiple unique keys.

5. **Purpose:**
   - Unique keys are used to ensure that the data in the column(s) remains unique across the rows. They are often used for columns that should not contain duplicate values, like email addresses or usernames.

### Comparison Summary

- **Uniqueness:** Both enforce uniqueness on the specified column(s).
- **Nullability:** Primary keys cannot contain NULL values; unique keys can.
- **Number per Table:** Only one primary key per table; multiple unique keys per table are allowed.
- **Index Type:** Primary keys generally create a clustered index (if one does not already exist); unique keys can create either clustered or non-clustered indexes.
- **Purpose:** Primary keys uniquely identify each record in the table, often used as a reference by foreign keys. Unique keys ensure data integrity for specific columns but do not necessarily identify records uniquely.

Understanding these differences helps in designing database schemas effectively, ensuring data integrity and optimizing query performance.

			
				<H2>SQL Server in Azure VM vs. Azure SQL Database</H2>
				
					<TABLE>
						<TR><TD CLASS="tabhead">SQL Server in Azure VM</TD><TD CLASS="tabhead">Azure SQL Database</TD></TR>
						<TR>
							<TD CLASS="tabdata">Access a VM with SQL Server.</TD>
							<TD CLASS="tabdata">Access a database.</TD></TR>
						<TR>
							<TD CLASS="tabdata">Manage SQL Server and Windows: HA, Backups, Patching.</TD>
							<TD CLASS="tabdata">Database is fully managed: HA, Backups, Patching.</TD></TR>
						<TR>
							<TD CLASS="tabdata">Can run any SQL Server version and edition.</TD>
							<TD CLASS="tabdata">Runs latest SQL Server version, based on Enterprise Edition.</TD></TR>
						<TR>
							<TD CLASS="tabdata">Full on-premise compatibility.</TD>
							<TD CLASS="tabdata">Incomplete on-premise compatibility (no jobs, linked servers, FileStream).</TD></TR>
						<TR>
							<TD CLASS="tabdata">Different VM sizes: A0 to A16, D-Series.</TD>
							<TD CLASS="tabdata">Different database sizes: Basic to Premium.</TD></TR>
						<TR>
							<TD CLASS="tabdata">VM availability SLA: 99.95% (can achieve higher availability ~99.99% through AlwaysON).</TD>
							<TD CLASS="tabdata">Database availability: 99.99%</TD></TR>
						<TR>
							<TD CLASS="tabdata">Reuse on-premise infrastructure (ex: Active Directory).</TD>
							<TD CLASS="tabdata"></TD></TR>
					</TABLE>
					
				<H2>sp_help_revlogin limitation (test this)</H2>
				
					<P>A login that has server role (ex: sysadmin role) will be migrated, the script will only create the login, excluding the role.</P>
					
				<H2>Useful Trace Flags</H2>
				
					<UL>
						<LI>3226 - Stops successful database backups from logging a message in the SQL Server error log and the System Event log.</LI>
						<LI>3042 - Causes the backup operation to bypass the default backup compression pre-allocation algorithm. This trace flag is useful if you need to save on space by allocating only the actual size required for the compressed backup. However, using this trace flag might cause a slight performance penalty (a possible increase in the duration of the backup operation).</LI>
						<LI>7745 - For Query Store, do not flush data to disk on database shutdown. I would rather lose some Query Store data than wait for this operation during shutdown.</LI>
						<LI>7752 - Asynchronous load of Query Store. I would rather get databases up faster than wait for Query Store to finish loading.</LI>
					</UL>
					
				<H2>Identify Current Node used in a Cluster.</H2>

<PRE>
SELECT SERVERPROPERTY('ComputerNamePhysicalNetBIOS')

</PRE>

				<H2>SPIDs</H2>
				
					<P>How to determine if the SPID is a system process?</P>
						<UL>
							<LI>If the SPID has an "s" at the end. (ex: 04/20/2021 16:25:32,spid27s,Unknown,Arithmetic overflow error converting expression to data type bigint.)</LI>
							<LI>NORMALLY, SPID 1 to 50 is reserved for SQL Server internal processes, and the user process starts from SPID 51 (sessions over 50 may be system as well.). To be more accurate, use the is_user_process column in sys.dm_exec_sessions to tell which are system and which are user</LI>
							<LI>If you kill a SPID, then do a reboot while it is doing a rollback, when SQL starts, the database that was doing a rollback will go into recovery (doing the rollback) until it's done. Meaning, it won't come online until it's done.</LI>
						</UL>
				
				<H2>License Keys</H2>
				
					<TABLE WIDTH=100%>
						<TR><TD CLASS="tabhead">Version</TD>
							<TD CLASS="tabhead">Key</TD>
						</TR>
						<TR><TD CLASS="tabdata">SQL Server 2012 ?</TD>
							<TD CLASS="tabdata">748RB-X4T6B-MRM7V-RTVFF-CHC8H</TD>
						</TR>
						<TR><TD CLASS="tabdata">SQL Server 2014 Enterprise Edition</TD>
							<TD CLASS="tabdata">P7FRV-Y6X6Y-Y8C6Q-TB4QR-DMTTK</TD>
						</TR>
						<TR><TD CLASS="tabdata">SQL Server 2017 Enterprise Edition</TD>
							<TD CLASS="tabdata">TDKQD-PKV44-PJT4N-TCJG2-3YJ6B / 6GPYM-VHN83-PHDM2-Q9T2R-KBV83</TD>
						</TR>
						</TR>
						<TR><TD CLASS="tabdata">SQL Server 2019 Enterprise Edition</TD>
							<TD CLASS="tabdata">HMWJ3-KY3J2-NMVD7-KG4JR-X2G8G</TD>
						</TR>
						<TR><TD CLASS="tabdata">SQL Server 2022 ?</TD>
							<TD CLASS="tabdata">FG86G-CHH2T-CB7NJ-XT7D2-V8V4X</TD>
						</TR>
						<TR><TD CLASS="tabdata">Visual Studio 2013</TD>
							<TD CLASS="tabdata">BWG7X-J98B3-W34RT-33B3R-JVYW9</TD>
						</TR>
						<TR><TD CLASS="tabdata">Visual Studio 2015 Enterprise Edition</TD>
							<TD CLASS="tabdata">2XNFG-KFHR8-QV3CP-3W6HT-683CH / HM6NR-QXX7C-DFW2Y-8B82K-WTYJV</TD>
						</TR>
					</TABLE>
					
		</DIV>
	</BODY>	
</HTML>